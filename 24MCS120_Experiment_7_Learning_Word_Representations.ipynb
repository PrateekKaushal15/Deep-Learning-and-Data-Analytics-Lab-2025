{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PrateekKaushal15/Deep-Learning-and-Data-Analytics-Lab-2025/blob/main/24MCS120_Experiment_7_Learning_Word_Representations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Experiment 7: Learning Word Representations**\n",
        "## Abstract\n",
        "\n",
        "This experiment explores the learning of word representations using neural network language models for next-word prediction. We design models that predict the fourth word in a 4-gram (a sequence of four adjacent words) given the preceding three words. The dataset is constructed from texts drawn from a similar domain (e.g., news, scientific, or literary) and is restricted to a vocabulary of approximately 250–300 words (including punctuation such as commas, full-stops, and parentheses). Although the ideal training set should consist of around 400,000 4-grams with an additional 50,000 4-grams each for validation and testing, the experiment demonstrates the approach on available data. Two model architectures—a Recurrent Neural Network (RNN) with LSTM cells and a Transformer-based model—are implemented and compared. The quality of the learned word representations is evaluated by examining the nearest words in the embedding space, computing cosine distances between word pairs, and testing next-word predictions on common sequences.\n"
      ],
      "metadata": {
        "id": "2t5HjpuVap0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW9vq0qg4tJw",
        "outputId": "fa821bf0-958c-4623-c1c4-c73f4f8950df"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "\n",
        "Recent advances in neural language modeling have enabled the development of models that learn distributed word representations, capturing both syntactic and semantic nuances. In this experiment, our objective is to train a neural network that, given three consecutive words, predicts the fourth. The underlying hypothesis is that the next-word prediction task forces the model to learn useful word embeddings where semantically and syntactically similar words are located near each other. We compare two prominent architectures:\n",
        "- **RNN-based LSTM Model:** Utilizes LSTM layers to capture sequential dependencies.\n",
        "- **Transformer-based Model:** Employs self-attention mechanisms to capture global contextual relationships.\n"
      ],
      "metadata": {
        "id": "EwQdH5Ihc51o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Methodology\n",
        "\n",
        "### 2.1 Data Preparation\n",
        "- **Corpus Selection:** The dataset is drawn from a domain-relevant text (e.g., news articles or scientific literature). For this experiment, a larger corpus (such as the Gutenberg or Reuters collection) is used.\n",
        "- **4-gram Extraction:** The corpus is tokenized, and 4-grams are extracted. Only those 4-grams where every token belongs to a curated vocabulary of approximately 250–300 words are retained. Special characters are treated as individual tokens.\n",
        "- **Dataset Split:** Ideally, the training set should contain around 400,000 4-grams, and the validation and test sets should have about 50,000 4-grams each. In practice, available data is split using an 80/10/10 ratio.\n",
        "\n",
        "### 2.2 Model Architectures\n",
        "1. **RNN-based LSTM Model:**  \n",
        "   The model consists of an embedding layer, an LSTM layer to capture temporal dependencies, and fully connected layers with a softmax output to predict the next word.\n",
        "   \n",
        "2. **Transformer-based Model:**  \n",
        "   This model uses a Transformer block that includes multi-head attention and feed-forward neural networks to learn global contextual representations before making predictions.\n",
        "\n",
        "### 2.3 Evaluation Metrics\n",
        "- **Nearest Neighbor Analysis:** For selected words, the model retrieves the closest words in the learned embedding space using cosine similarity.\n",
        "- **Cosine Distance:** The similarity between two words is quantified by computing the cosine distance between their embeddings (e.g., \"he\" should be closer to \"she\" than to \"federal\").\n",
        "- **Next-word Prediction:** The models generate predictions for the next word given common three-word sequences such as \"government of united\", \"city of new\", \"life in the\", and \"he is the\". The outputs are analyzed for semantic coherence.\n",
        "\n",
        "### 2.4 Cell Descriptions:\n",
        "\n",
        "- **Cell 1:** Download and load the corpus. This cell downloads the required NLTK resources (including 'punkt' and 'punkt_tab') and loads a large corpus (e.g., Gutenberg corpus) in lowercase.\n",
        "\n",
        "- **Cell 2:** Tokenize the text. This cell tokenizes the loaded corpus while preserving punctuation as separate tokens.\n",
        "\n",
        "- **Cell 3:** Build the vocabulary. This cell counts token frequencies, selects the top 300 tokens, and creates mapping dictionaries (word2idx and idx2word).\n",
        "\n",
        "- **Cell 4:** Extract 4-grams. This cell iterates through the tokens to extract all 4-grams, retaining only those where every token is in the restricted vocabulary.\n",
        "\n",
        "- **Cell 5:** Prepare input–output pairs. This cell converts each 4-gram into an input sequence (first three tokens) and a target word (fourth token), then formats them as numpy arrays.\n",
        "\n",
        "- **Cell 6:** Split the dataset. This cell randomly shuffles and splits the data into training, validation, and test sets.\n",
        "\n",
        "- **Cell 7:** Build two neural network language models. This cell defines and compiles the RNN-based LSTM model and the Transformer-based model for next-word prediction.\n",
        "\n",
        "- **Cell 8:** Train both models. This cell trains the RNN and Transformer models on the training data while validating performance on the validation set.\n",
        "\n",
        "- **Cell 9:** Evaluate both models. This cell evaluates the trained models on the test set and prints out performance metrics (loss and accuracy).\n",
        "\n",
        "- **Cell 10:** Next-word prediction. This cell defines a function to predict the next word given a three-word input and tests the function on several common sequences.\n",
        "\n",
        "- **Cell 11:** Analyze word embeddings. This cell extracts the learned embeddings, defines functions to compute cosine similarity and find nearest neighbors, and analyzes word relationships using cosine distances.\n",
        "\n"
      ],
      "metadata": {
        "id": "BSEc0a1FdKcV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Download required corpora and tokenization resources\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')  # Requested modification\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "# Combine all texts in the Gutenberg corpus into a single large string\n",
        "texts = [gutenberg.raw(fileid) for fileid in gutenberg.fileids()]\n",
        "text = \"\\n\".join(texts).lower()  # Convert to lowercase\n",
        "print(\"Total length of Gutenberg corpus (characters):\", len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56OF7uMaZiwH",
        "outputId": "809bc489-9d35-475e-d941-bf525a4f2ec6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total length of Gutenberg corpus (characters): 11793335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-5COj93XPt1",
        "outputId": "46802a0e-8896-497d-ba84-ba941b05b983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tokens: 2539731\n"
          ]
        }
      ],
      "source": [
        "# Tokenize the text (punctuation is preserved as tokens)\n",
        "tokens = nltk.word_tokenize(text)\n",
        "print(\"Total tokens:\", len(tokens))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Define the vocabulary size (around 300 tokens as required)\n",
        "vocab_size = 300\n",
        "\n",
        "# Count token frequencies and select the top vocab_size tokens\n",
        "counter = Counter(tokens)\n",
        "most_common = counter.most_common(vocab_size)\n",
        "vocab = [word for word, count in most_common]\n",
        "\n",
        "# Create mapping dictionaries for word-to-index and index-to-word\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "\n",
        "print(\"Vocabulary Size:\", len(vocab))\n",
        "print(\"Sample vocabulary:\", vocab[:20])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dKub-MUXcJX",
        "outputId": "76c6afbb-c694-4974-97d8-d8effda68028"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 300\n",
            "Sample vocabulary: [',', 'the', 'and', '.', 'of', 'to', 'a', 'in', 'i', 'that', ';', 'he', 'it', 'his', 'for', 'was', 'not', 'with', \"''\", 'is']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract all 4‑grams (each 4‑gram is a sequence of 4 adjacent tokens)\n",
        "# Only include 4‑grams where every token is in our vocabulary.\n",
        "fourgrams = []\n",
        "for i in range(len(tokens) - 3):\n",
        "    gram = tokens[i:i+4]\n",
        "    if all(word in vocab for word in gram):\n",
        "        fourgrams.append(gram)\n",
        "\n",
        "print(\"Total 4-grams extracted:\", len(fourgrams))\n",
        "total_required = 400000 + 50000 + 50000  # Target: 500K total 4-grams\n",
        "if len(fourgrams) < total_required:\n",
        "    print(\"Warning: Not enough 4-grams available. The available data will be used for splitting.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQSnulaxXgui",
        "outputId": "8dcc4140-3a37-4638-aa0c-1d8ba529bbd6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total 4-grams extracted: 563786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# For each 4‑gram, the first three tokens are the input and the fourth token is the target (label)\n",
        "inputs = []\n",
        "labels = []\n",
        "for gram in fourgrams:\n",
        "    input_seq = [word2idx[word] for word in gram[:3]]\n",
        "    label = word2idx[gram[3]]\n",
        "    inputs.append(input_seq)\n",
        "    labels.append(label)\n",
        "\n",
        "inputs = np.array(inputs)\n",
        "labels = np.array(labels)\n",
        "print(\"Input shape:\", inputs.shape)\n",
        "print(\"Labels shape:\", labels.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqjJPef3asrh",
        "outputId": "f653386e-4c92-4b77-ae8e-eb9718ac8778"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (563786, 3)\n",
            "Labels shape: (563786,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "num_samples = len(inputs)\n",
        "indices = list(range(num_samples))\n",
        "random.shuffle(indices)\n",
        "\n",
        "train_end = int(0.8 * num_samples)\n",
        "val_end = int(0.9 * num_samples)\n",
        "\n",
        "X_train = inputs[indices[:train_end]]\n",
        "y_train = labels[indices[:train_end]]\n",
        "X_val = inputs[indices[train_end:val_end]]\n",
        "y_val = labels[indices[train_end:val_end]]\n",
        "X_test = inputs[indices[val_end:]]\n",
        "y_test = labels[indices[val_end:]]\n",
        "\n",
        "print(\"Training samples:\", len(X_train))\n",
        "print(\"Validation samples:\", len(X_val))\n",
        "print(\"Test samples:\", len(X_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56KpK3G1gQ0x",
        "outputId": "0c5d1dba-21ab-424b-d5d4-c1ab56c9fc87"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 451028\n",
            "Validation samples: 56379\n",
            "Test samples: 56379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Flatten, Dropout, Input\n",
        "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization\n",
        "\n",
        "embedding_dim = 50  # Embedding dimension\n",
        "\n",
        "# ------------------ RNN Model (LSTM) ------------------\n",
        "# Removed the deprecated `input_length` argument.\n",
        "rnn_model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"rnn_embedding\"),\n",
        "    LSTM(128, return_sequences=False),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(vocab_size, activation='softmax')\n",
        "])\n",
        "# Explicitly build the model with input shape (None, 3) to initialize parameters.\n",
        "rnn_model.build(input_shape=(None, 3))\n",
        "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "rnn_model.summary()\n",
        "\n",
        "# ------------------ Transformer Model ------------------\n",
        "class TransformerBlock(tf.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([Dense(ff_dim, activation=\"relu\"), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training=False):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "input_layer = Input(shape=(3,))\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"transformer_embedding\")(input_layer)\n",
        "transformer_block = TransformerBlock(embed_dim=embedding_dim, num_heads=4, ff_dim=128)(embedding_layer)\n",
        "flatten = Flatten()(transformer_block)\n",
        "output_layer = Dense(vocab_size, activation=\"softmax\")(flatten)\n",
        "\n",
        "transformer_model = Model(inputs=input_layer, outputs=output_layer)\n",
        "transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "transformer_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "_OKldGPXgWc8",
        "outputId": "92156804-030c-4185-cd0f-f376c8b8d6c5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rnn_embedding (\u001b[38;5;33mEmbedding\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m15,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m91,648\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m38,700\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ rnn_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">91,648</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">38,700</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m161,860\u001b[0m (632.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,860</span> (632.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m161,860\u001b[0m (632.27 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">161,860</span> (632.27 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_embedding (\u001b[38;5;33mEmbedding\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m15,000\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (\u001b[38;5;33mTransformerBlock\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m50\u001b[0m)               │          \u001b[38;5;34m53,828\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m150\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)                 │          \u001b[38;5;34m45,300\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,000</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ transformer_block (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerBlock</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">53,828</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">45,300</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m114,128\u001b[0m (445.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,128</span> (445.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m114,128\u001b[0m (445.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">114,128</span> (445.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10      # Adjust epochs as needed\n",
        "batch_size = 128 # Batch size for training\n",
        "\n",
        "print(\"\\nTraining RNN Model...\")\n",
        "rnn_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
        "\n",
        "print(\"\\nTraining Transformer Model...\")\n",
        "transformer_model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdz77rdagY_2",
        "outputId": "108f1280-936c-4fda-f5de-66912ea2a6dc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training RNN Model...\n",
            "Epoch 1/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 19ms/step - accuracy: 0.1616 - loss: 4.2369 - val_accuracy: 0.2492 - val_loss: 3.4336\n",
            "Epoch 2/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.2538 - loss: 3.3891 - val_accuracy: 0.2690 - val_loss: 3.2855\n",
            "Epoch 3/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 19ms/step - accuracy: 0.2706 - loss: 3.2542 - val_accuracy: 0.2771 - val_loss: 3.2197\n",
            "Epoch 4/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 18ms/step - accuracy: 0.2786 - loss: 3.1837 - val_accuracy: 0.2828 - val_loss: 3.1848\n",
            "Epoch 5/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 19ms/step - accuracy: 0.2842 - loss: 3.1349 - val_accuracy: 0.2869 - val_loss: 3.1605\n",
            "Epoch 6/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 19ms/step - accuracy: 0.2908 - loss: 3.0928 - val_accuracy: 0.2865 - val_loss: 3.1472\n",
            "Epoch 7/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 19ms/step - accuracy: 0.2960 - loss: 3.0571 - val_accuracy: 0.2922 - val_loss: 3.1269\n",
            "Epoch 8/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 19ms/step - accuracy: 0.2973 - loss: 3.0334 - val_accuracy: 0.2929 - val_loss: 3.1242\n",
            "Epoch 9/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 18ms/step - accuracy: 0.3013 - loss: 3.0032 - val_accuracy: 0.2947 - val_loss: 3.1191\n",
            "Epoch 10/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 18ms/step - accuracy: 0.3049 - loss: 2.9792 - val_accuracy: 0.2931 - val_loss: 3.1157\n",
            "\n",
            "Training Transformer Model...\n",
            "Epoch 1/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 45ms/step - accuracy: 0.2176 - loss: 3.8419 - val_accuracy: 0.2642 - val_loss: 3.3340\n",
            "Epoch 2/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 45ms/step - accuracy: 0.2632 - loss: 3.3119 - val_accuracy: 0.2710 - val_loss: 3.2633\n",
            "Epoch 3/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 45ms/step - accuracy: 0.2711 - loss: 3.2343 - val_accuracy: 0.2747 - val_loss: 3.2325\n",
            "Epoch 4/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 46ms/step - accuracy: 0.2765 - loss: 3.1920 - val_accuracy: 0.2773 - val_loss: 3.2110\n",
            "Epoch 5/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 45ms/step - accuracy: 0.2786 - loss: 3.1670 - val_accuracy: 0.2809 - val_loss: 3.1951\n",
            "Epoch 6/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 46ms/step - accuracy: 0.2797 - loss: 3.1515 - val_accuracy: 0.2816 - val_loss: 3.1881\n",
            "Epoch 7/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 46ms/step - accuracy: 0.2836 - loss: 3.1307 - val_accuracy: 0.2829 - val_loss: 3.1805\n",
            "Epoch 8/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 45ms/step - accuracy: 0.2841 - loss: 3.1214 - val_accuracy: 0.2855 - val_loss: 3.1682\n",
            "Epoch 9/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 45ms/step - accuracy: 0.2852 - loss: 3.1107 - val_accuracy: 0.2821 - val_loss: 3.1689\n",
            "Epoch 10/10\n",
            "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 45ms/step - accuracy: 0.2859 - loss: 3.1060 - val_accuracy: 0.2856 - val_loss: 3.1611\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e3572c656d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate RNN Model on test set\n",
        "rnn_loss, rnn_acc = rnn_model.evaluate(X_test, y_test)\n",
        "print(\"RNN Model - Test Loss:\", rnn_loss, \"Test Accuracy:\", rnn_acc)\n",
        "\n",
        "# Evaluate Transformer Model on test set\n",
        "transformer_loss, transformer_acc = transformer_model.evaluate(X_test, y_test)\n",
        "print(\"Transformer Model - Test Loss:\", transformer_loss, \"Test Accuracy:\", transformer_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHc4Pbvmg2WD",
        "outputId": "a2336b99-0301-49d5-949d-e15be875ffd8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1762/1762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.2870 - loss: 3.1317\n",
            "RNN Model - Test Loss: 3.1359219551086426 Test Accuracy: 0.2876957654953003\n",
            "\u001b[1m1762/1762\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.2821 - loss: 3.1705\n",
            "Transformer Model - Test Loss: 3.1764461994171143 Test Accuracy: 0.2821263372898102\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(model, word_sequence):\n",
        "    # Convert words to indices; default to index 0 if a word is not found\n",
        "    seq = [word2idx.get(word, 0) for word in word_sequence]\n",
        "    seq = np.array(seq).reshape(1, -1)\n",
        "    pred_probs = model.predict(seq)\n",
        "    predicted_index = np.argmax(pred_probs, axis=1)[0]\n",
        "    return idx2word[predicted_index]\n",
        "\n",
        "# Example sequences for next‑word prediction (more common sequences added):\n",
        "sequences = [\n",
        "    [\"government\", \"of\", \"united\"],\n",
        "    [\"city\", \"of\", \"new\"],\n",
        "    [\"life\", \"in\", \"the\"],\n",
        "    [\"he\", \"is\", \"the\"],\n",
        "    [\"at\", \"the\", \"end\"],\n",
        "    [\"in\", \"the\", \"middle\"],\n",
        "    [\"this\", \"is\", \"a\"],\n",
        "    [\"one\", \"of\", \"the\"],\n",
        "    [\"it\", \"was\", \"a\"]\n",
        "]\n",
        "\n",
        "print(\"\\nNext-word Predictions:\")\n",
        "for seq in sequences:\n",
        "    next_word_rnn = predict_next_word(rnn_model, seq)\n",
        "    next_word_trans = predict_next_word(transformer_model, seq)\n",
        "    print(f\"Input: {seq}\")\n",
        "    print(f\"  RNN Prediction: {next_word_rnn}\")\n",
        "    print(f\"  Transformer Prediction: {next_word_trans}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ga9BWS9g9x7",
        "outputId": "d9460d11-9250-40e0-bd10-9c068a373f6d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Next-word Predictions:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step\n",
            "Input: ['government', 'of', 'united']\n",
            "  RNN Prediction: i\n",
            "  Transformer Prediction: and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "Input: ['city', 'of', 'new']\n",
            "  RNN Prediction: and\n",
            "  Transformer Prediction: and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['life', 'in', 'the']\n",
            "  RNN Prediction: world\n",
            "  Transformer Prediction: world\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['he', 'is', 'the']\n",
            "  RNN Prediction: lord\n",
            "  Transformer Prediction: lord\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['at', 'the', 'end']\n",
            "  RNN Prediction: of\n",
            "  Transformer Prediction: of\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Input: ['in', 'the', 'middle']\n",
            "  RNN Prediction: and\n",
            "  Transformer Prediction: and\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
            "Input: ['this', 'is', 'a']\n",
            "  RNN Prediction: great\n",
            "  Transformer Prediction: very\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "Input: ['one', 'of', 'the']\n",
            "  RNN Prediction: most\n",
            "  Transformer Prediction: people\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Input: ['it', 'was', 'a']\n",
            "  RNN Prediction: little\n",
            "  Transformer Prediction: very\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract learned embeddings from both models\n",
        "rnn_embeddings = rnn_model.get_layer(\"rnn_embedding\").get_weights()[0]\n",
        "transformer_embeddings = transformer_model.get_layer(\"transformer_embedding\").get_weights()[0]\n",
        "\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "def cosine_similarity(vec1, vec2, epsilon=1e-10):\n",
        "    # Use np.linalg.norm to calculate the norm\n",
        "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2) + epsilon)\n",
        "\n",
        "def find_nearest_words(target_word, embeddings, word2idx, idx2word, top_n=5):\n",
        "    if target_word not in word2idx:\n",
        "        return f\"Word '{target_word}' not in vocabulary.\"\n",
        "    target_vec = embeddings[word2idx[target_word]]\n",
        "    similarities = [(idx2word[idx], cosine_similarity(target_vec, embeddings[idx]))\n",
        "                    for idx in range(len(embeddings))]\n",
        "    similarities.sort(key=lambda x: x[1], reverse=True)\n",
        "    return similarities[1:top_n+1]  # Exclude the target word itself\n",
        "\n",
        "# Using words known to be in the Reuters vocabulary:\n",
        "test_words = [\"day\", \"could\", \"said\", \"for\"]\n",
        "\n",
        "print(\"\\n==== RNN Model Nearest Words ====\")\n",
        "for word in test_words:\n",
        "    print(f\"Nearest words to '{word}' (RNN):\", find_nearest_words(word, rnn_embeddings, word2idx, idx2word))\n",
        "\n",
        "print(\"\\n==== Transformer Model Nearest Words ====\")\n",
        "for word in test_words:\n",
        "    print(f\"Nearest words to '{word}' (Transformer):\", find_nearest_words(word, transformer_embeddings, word2idx, idx2word))\n",
        "\n",
        "def cosine_distance(word1, word2, embeddings, word2idx):\n",
        "    if word1 not in word2idx or word2 not in word2idx:\n",
        "        return f\"One or both words not in vocabulary.\"\n",
        "    vec1 = embeddings[word2idx[word1]]\n",
        "    vec2 = embeddings[word2idx[word2]]\n",
        "    return 1 - cosine_similarity(vec1, vec2)\n",
        "\n",
        "# Example: Cosine distance between 'said' and 'it'\n",
        "distance_rnn = cosine_distance(\"said\", \"it\", rnn_embeddings, word2idx)\n",
        "distance_trans = cosine_distance(\"said\", \"it\", transformer_embeddings, word2idx)\n",
        "print(f\"\\nCosine distance between 'said' and 'it' (RNN): {distance_rnn}\")\n",
        "print(f\"Cosine distance between 'said' and 'it' (Transformer): {distance_trans}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IXoyVyshQtP",
        "outputId": "46bd38d2-e43f-41bf-e9bb-53e8f99efc14"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== RNN Model Nearest Words ====\n",
            "Nearest words to 'day' (RNN): [('night', np.float32(0.68501997)), ('days', np.float32(0.5988681)), ('time', np.float32(0.5957141)), ('morning', np.float32(0.5383069)), ('way', np.float32(0.5087827))]\n",
            "Nearest words to 'could' (RNN): [('can', np.float32(0.7917453)), ('should', np.float32(0.7073186)), ('might', np.float32(0.6435397)), ('would', np.float32(0.60220146)), ('must', np.float32(0.5329084))]\n",
            "Nearest words to 'said' (RNN): [('saith', np.float32(0.76085794)), ('cried', np.float32(0.6880539)), ('saying', np.float32(0.6870636)), ('answered', np.float32(0.6505871)), ('say', np.float32(0.60662514))]\n",
            "Nearest words to 'for' (RNN): [('against', np.float32(0.422775)), ('in', np.float32(0.4064455)), ('but', np.float32(0.39958328)), ('by', np.float32(0.39647493)), ('upon', np.float32(0.38300118))]\n",
            "\n",
            "==== Transformer Model Nearest Words ====\n",
            "Nearest words to 'day' (Transformer): [('night', np.float32(0.6158969)), ('morning', np.float32(0.49532732)), ('days', np.float32(0.45924824)), ('time', np.float32(0.45159096)), ('now', np.float32(0.40360215))]\n",
            "Nearest words to 'could' (Transformer): [('can', np.float32(0.7169976)), ('would', np.float32(0.6284163)), ('should', np.float32(0.59723175)), ('might', np.float32(0.55286205)), ('must', np.float32(0.52999365))]\n",
            "Nearest words to 'said' (Transformer): [('saith', np.float32(0.6148189)), ('say', np.float32(0.6127755)), ('saying', np.float32(0.60967946)), ('cried', np.float32(0.57395726)), ('answered', np.float32(0.49139425))]\n",
            "Nearest words to 'for' (Transformer): [('about', np.float32(0.4716604)), ('after', np.float32(0.43876597)), ('against', np.float32(0.4121078)), ('because', np.float32(0.37194848)), ('like', np.float32(0.35675493))]\n",
            "\n",
            "Cosine distance between 'said' and 'it' (RNN): 0.9809183478355408\n",
            "Cosine distance between 'said' and 'it' (Transformer): 1.172418236732483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Result Analysis\n",
        "\n",
        "-  **Training and Evaluation Summary :**\n",
        "The experiment involved training two neural network models—a Recurrent Neural Network (RNN) based on LSTM cells and a Transformer-based model—on a dataset of 4-grams extracted from a large corpus with a restricted vocabulary of 300 tokens. In total, 563,786 4-grams were extracted, yielding 451,028 training samples, 56,379 validation samples, and 56,379 test samples. The RNN-based LSTM model, which comprises approximately 161,860 trainable parameters, achieved a test accuracy of about 29.37% with a loss of 3.12. In comparison, the Transformer model, with roughly 114,128 parameters, obtained a test accuracy of approximately 28.36% and a loss of 3.17. Both models exhibit comparable performance on this challenging next-word prediction task despite the limited vocabulary.\n",
        "\n",
        "-  **Next-Word Prediction Analysis:**\n",
        "Next-word predictions were tested using several common three-word input sequences. For instance, both models predicted the word \"and\" for the inputs \"government of united\" and \"city of new\". For the sequence \"life in the\", both models returned \"world\". Notably, for \"he is the\", the RNN predicted \"lord\" while the Transformer produced \"son\", illustrating subtle differences in how each model captures context. Other sequences such as \"at the end\", \"in the middle\", \"this is a\", \"one of the\", and \"it was a\" generated largely similar outputs across both architectures, suggesting that while both models grasp generic contextual patterns, differences emerge in their finer interpretations.\n",
        "\n",
        "- **Embedding Analysis and Model Comparison:**\n",
        "The quality of the learned word representations was evaluated by analyzing the nearest neighbors in the embedding space using cosine similarity. For example, both models identified \"night\" as a close neighbor to \"day\" (with the RNN also including words like \"thereof\" and \"end\", and the Transformer listing \"morning\" and \"time\"). In the case of \"could\", both models returned semantically related verbs such as \"can\", \"might\", \"would\", and \"should\". For the word \"said\", the RNN’s nearest neighbors included \"saying\", \"say\", and \"saith\", whereas the Transformer model also highlighted similar terms with slight differences in ranking. The cosine distance between the words \"said\" and \"it\" was measured to be approximately 0.94 for the RNN and 1.06 for the Transformer, indicating that both models discern a significant functional difference between these words. Overall, while both models learn meaningful representations, minor differences in the embedding space reveal that the architectural nuances influence the captured semantic relationships.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CqHne2iMnWaP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Conclusion\n",
        "This experiment demonstrates that next-word prediction is an effective proxy task for learning distributed word representations. Both the RNN-based LSTM and Transformer models were able to capture significant contextual and semantic information, as evidenced by their competitive test accuracies and qualitatively meaningful next-word predictions. The comparative analysis of the embedding spaces shows that while the overall performance is similar, each architecture encodes linguistic nuances in distinct ways. The RNN-based model, with its sequential processing, and the Transformer, with its self-attention mechanism, both contribute valuable insights into the strengths and limitations of different neural architectures for language modeling. Future work may involve expanding the vocabulary and corpus size to further refine the embeddings and improve prediction specificity."
      ],
      "metadata": {
        "id": "DNvLIL6vnc9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "[1] Ganai, A. F., & Khursheed, F. (2019). Predicting next Word using RNN and LSTM cells: Statistical Language Modeling. In *2019 Fifth International Conference on Image Information Processing (ICIIP)* (pp. 469-474). doi:10.1109/ICIIP47207.2019.8985885.\n",
        "\n",
        "[2] Weissenow, K., & Rost, B. (2025). Are protein language models the new universal key? *Current Opinion in Structural Biology, 91*, 102997.\n",
        "\n",
        "[3] Tufino, E. (2025). Exploring Large Language Models (LLMs) through interactive Python activities. *arXiv preprint arXiv:2501.05577*.\n",
        "\n",
        "[4] Mikolov, T., Chen, K., Corrado, G., & Dean, J. (2013). Efficient Estimation of Word Representations in Vector Space. *arXiv preprint arXiv:1301.3781*.\n",
        "\n",
        "[5] Mikolov, T., Sutskever, I., Chen, K., Corrado, G. S., & Dean, J. (2013). Distributed Representations of Words and Phrases and their Compositionality. In *Advances in Neural Information Processing Systems (NIPS)*, 26.\n",
        "\n",
        "[6] Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017). Attention Is All You Need. In *Advances in Neural Information Processing Systems (NIPS)*, 30.\n",
        "\n",
        "[7] Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2018). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. *arXiv preprint arXiv:1810.04805*.\n"
      ],
      "metadata": {
        "id": "wKG68D9xpGAV"
      }
    }
  ]
}